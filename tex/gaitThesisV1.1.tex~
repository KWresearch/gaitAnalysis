%\documentclass[onecolumn,prl,nobalancelastpage,aps,10pt]{revtex4-1}%\documentclass[rmp,preprint]{revtex4-1}\documentclass[11pt]{article} % Try also "scrartcl" or "paper"\linespread{1.15} \usepackage[margin=2.3cm]{geometry}   % to change margins \usepackage{titling,cite,subfig}             % Uncomment both to    \setlength{\droptitle}{0cm}     % change title position \title{%\vspace{-1.5cm}            % Another way to doFeature Descriptors for Gait Analysis From Depth Sensors}\usepackage{graphicx,bm,subfig,amsmath,amsfonts,listings,url}\usepackage[page]{appendix}\usepackage{gensymb}\usepackage{color}\usepackage{microtype}%\renewcommand{\thesection}{\arabic{section}}%\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}%\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}\DeclareMathOperator*{\argmin}{arg\,min}% Fix references\makeatletter\renewcommand{\p@subsection}{}\renewcommand{\p@subsubsection}{}\makeatother\usepackage{bibentry}\newcommand{\comment}[1]{}\begin{document}\comment{A statement of the aims and objectives of the project.A description of the background and context of the project and its relation to work already done in the area. (Note that while you are free to re-use work from your research review here, it would normally be appropriate to tailor your earlier work to better suport the final contributions of the project. Typically you will include new related work which was found to be important, while excluding previously studied work which has become irrelevant, and modifying your earlier write-up with more or less detail, as required).A description of the work carried out. This should include details of technical or scientific problems tackled, solutions proposed, and the design and development of software.A description and analysis of results obtained.A critical evaluation of the work. This is an analysis of the extent to which the project has achieved its objectives, and whether the choices that were made were, with hindsight, the best ones.Suggestions on possible improvements and/or further work.	Introduction:		Discuss SPHERE, the need for in home gait analysis, references that show this is possible from kinect, 	The existing pipeline:		Kinect SDK skeletons... shotton et al.		same as lit review, but go into more detail on the dimensionality reduction/manifold method	}\title{Feature Descriptors for Gait Analysis from Depth Sensors}\author{Ben Crabbe}\date{\today}\maketitle\section{Introduction}%SPHERE - a Sensor Platform for Healthcare in a Residential Environment, is a interdisciplinary research project being undertaken in Bristol which aims to help solve some of the problems currently faced by the healthcare system in the UK. The goal is to design a range of sensors to be fitted in residential environments that facilitate the care and rehabilitation of inhabitants.  %reference for some medical textbook?%A Kinect Based Approach to Assist in the Diagnosis and Quantification of Parkinson’s Disease%R. Torres, M. Huerta, R. Clotet, R. González, L. E. Sánchez, D. Rivas, M. Erazo%Parkinson’s Disease (PD) is a degenerative process of the central nervous system. Its main body symptoms are tremors, rigidity, bradykinesia and walking difficulty. These symptoms may increase and so it is necessary to have a constant and successful evaluation, so the PD patient may receive the appropriate treatment. There are systems that enable the monitoring of tremors based on sensors, most of them attached to the patient’s body. Some such systems comprise accelerometers or use of Nintendo Wii Remote sensors (NWR). As a proposal that allows true portability, without the attachment of a single sensor to the patient’s body, or need for batteries, this paper introduces a pilot system that allows to diagnose PD and evaluate its severity using Kinect sensors.%Problem- health home care gait analysisGait analysis plays an important part in the treatment and assessment of a number of medical conditions. Presently gait analysis is usually performed through a combination of visual assessment by an experienced physiotherapist, automated methods such as marker based motion capture, pressure sensitive walkways or accelerometers. It requires patients to travel to a gait assessment laboratory which is far from ideal for patients who have difficulty walking. %Solution - Sphere gait analysis pipelineThis problem, and a range of other healthcare challenges, is being tackled through research and development by the SPHERE (a Sensor Platform for Healthcare in a Residential Environment) group in Bristol. An automatic, in home, gait analysis pipeline has been designed~\cite{Paiement} which assesses the quality of a subjects movement using inexpensive RGB-D cameras such as the Microsoft Kinect.Currently this system uses joint position information captured by the OpenNI skeleton tracking software, based on the algorithm of~\cite{Shotton2011}. This skeleton tracking software infers the 3D coordinates of each of the body's relevant joints producing a $n_{joints} \times 3$ dimensional vector. This data is then processed using a manifold learning method, Diffusion maps~\cite{Coifman2006}, to reduce the dimensionality of the data. This method builds up a 3 dimensional manifold representation of the types of body configurations displayed in a dataset containing footage of the motion being measured. New skeleton data is then projected onto this manifold which, effectively parameterises the motion, removing the redundant information contained in the skeleton data, and enabling simple comparison of poses. \footnote{We will refer to the projected points in this space as the pose vector, and to the skeleton data as the body configuration or joint position vector.} Finally, a statistical model of normal gait is built up from the training data using these pose vectors. New data is compared with this model producing a gait quality score on a frame-by-frame basis.Since this system uses data driven, machine learning methods to learn both the manifold representation of pose and the model of normal motion, it can be applied to other types of movement quality assessment such a sports movement optimisation or physiotherapy exercise coaching. The system has been applied to a sitting-standing motion, to punching motions in boxing$^{how to site http://www.irc-sphere.ac.uk/work-package-2/movement-quality ?}$ and to people walking upstairs. %Limitation - doesn't work well in realisitic senariosOne issue currently limiting the effectiveness of this system is the fragility of the skeleton tracking software. Shotton et al's algorithm was designed for controlling entertainment/gaming systems with the user viewed frontally, within a range of 1-4m and at a pitch angle near 0$\degree$. Outside of these conditions skeletons become noisy and unreliable. Typically only a small fraction of data recorded from say a camera attached to the ceiling above the stairs is fit for use with the system. Increasing amount of usable data requires more intrusive camera placement which is to be avoided. The skeleton trackers also perform extremely poorly when props are involved in the scene, for example grasping a banister or a ball often leads to erroneous joint positions for that arm. It also struggles to accurately record sitting/standing motions.%AimsThe aim of this project is to develop a tailor made system for determining the reduced pose vector directly from RGB-D footage. To be effective this new component should enable the flexibility of the rest of the system by being able to record a wide range of motions. It should also work with an effective accuracy under the kinds of viewing angles produced by practical, unobtrusive, in home camera placements. This requires a data driven approach since the pose representation we wish to infer is not fixed, differing based on the body configurations presented in training data. %Simply we require a system that can be trained to regress from RGB-D image data to a point in a continuous 3d space.The methodology we find most suited to this task is a convolutional neural network (CNN). CNN's are a supervised learning method for extracting features, e.g. the pose vector, from images. Given training images labelled with the expected output the network learns to map from the input images to the output by adjusting the parameters in the network. Following training the network is then able to generalise to unseen data, producing an output inferred from the examples it has seen. CNNs have been effectively applied to 2D~human~pose estimation from RGB images~\cite{Toshev,Pfister,Li2014,Jain2013a,Jain2014,Tompson,Tompson2014} where the positions of joints in the image plane were inferred. In~\cite{Accv2014} they were also applied to 3D joint position estimation from RGB, where they were shown to have reasonable accuracy from a range of viewing angles when trained with data captured by 4 cameras placed around the subjects. They have also been shown to benefit from depth depth data in the tasks of object detection~\cite{Gupta2014}, object pose estimation~\cite{Schwarz2015} and object recognition~\cite{Alexandre2013}. %However this will be the first work, to our knowledge, that attempts a form of human pose estimation using depth data. For assessing the effectiveness of our solution we will focus on the staircase ascent motion, as this is the motion for which we possess the largest dataset. Refered to as the SPHERE staircase 2014 dataset~\cite{Paiement}, this includes 48 sequences of 12 individuals walking up stairs, captured by a Kinect v1 camera placed at the top of the stairs in a frontal and downward-looking position. It contains three types of abnormal gaits with lower-extremity musculoskeletal conditions, including freezing of gait and using a leading leg, left or right, in going up the stairs. All frames have been manually labelled as normal or abnormal by a qualified physiotherapist. There are 17 sequences of normal walking from 6 individuals and 31 sequences from the remaining 6 subjects with both normal and abnormal walking. The accuracy of our predicted pose vectors are measured by computing the mean squared error (MSE) of the produced pose vectors against the label values. We also measure the change in overall system performance (how well the measured gait quality score matches the score labelled by a trained physiotherapist). %State in general terms whether your project is more of Type I, II or III.%Generally the project can be seen as type I since it %Explain the main novelty and added value.To the best of my knowledge this project will be the first time that CNNs will be applied to a 3D human pose estimation task on RGB-D images. It will also be a novel combination of CNNs and manifold learning methods since what we are doing is simplifying the difficult task of human pose estimation through the dimensionality reduction stage. We find that this makes the CNN easier to train and more effective overall since it has far less outputs to specify. If this is proved to be the case it could potentially be applied to other tasks that have been attempted with CNNs such as human action recognition.\section{Related Work}Human pose estimation (HPE) is generally considered the task of measuring in 2D or 3D the free joint positions of the human body. Whilst this is somewhat different to our task, the pose vector  This is a difficult task for a number of reasons. Firstly the human body has a large number of degrees of freedom, producing a huge set of possible configurations, additionally, many of these configurations will cause some joints to be occluded when viewed from a single camera. Traditional methods such as marker based motion capture and some markless methods rely on multi camera scene capture to overcome these issues (reviewed in \cite{Moeslund2006}). However this is limiting as it demands recordings be taken in controlled environments using expensive and calibrated recording equipment. Markerless methods attempting HPE from single camera RGB images or video, reviewed in \cite{Hen2009,Poppe2007,Sminchisescu2006,Liu2015}, are "brittle" compared to the traditional optical motion capture due to lower accuracy and longer processing times.% One trend in these works was to use manifold learning methods to reduce the dimensionality of the pose space. These encodingWith the advent low cost commodity depth sensors challenging aspects of RGB HPE such as the variablity in human appearance and scene lighting were greatly simplified. RGB-D also provides richer data for infering 3D structure; human poses which could be appear identical when projected onto the 2D image plane can be distinguished. Full body HPE methods from single depth images are review in \cite{Helten2013}. With the Kinect sensor and its bundled software packages (Kinect SDK) low cost, flexible and reasonably accurate HPE is now availible and has been employed in a huge variety of scientific applications~\cite{Han2013,Giovanni}.The Kinect SDK and OpenNI skeleton trackers apply some unpublished  inter-frame tracking algorithm to the single frame pose measurements of~\cite{Shotton2011}. In this work Shotton et al. leveraged a large motion capture dataset which they re-targetted onto a variety of synthetic body models before rendering as if captured from a Kinect, simulating sensor noise, camera pose, and crop position. Using these generated depth images and a ground truth labeling of each pixel as one of 31 body parts they trained a randomised regression forrest to perform this body part classification at each pixel using simple and computationally efficient pixel wise features. They then use these classifications to infer actual joint position through a simple averaging and mean shift proceedure. The whole algorithm operates in real time on the computational resources allowed to them on the Xbox gaming consoles GPU. Further works Abit about HPE from multi camera views / marker based.Abit about depth imaging advances.Ubiquitousness of the kinect system.description of shotton etal .mention other methods. difference with our needs and these methods\section{Preprocessing}\label{sec:intro}All data used in this project SPHERE-staircase2014~dataset~\cite{Paiement}) \bibliographystyle{plain}\bibliography{library,myLib}\end{document}