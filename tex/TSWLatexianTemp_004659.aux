\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Paiement,Tao}
\citation{Shotton2011}
\citation{Coifman2006}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Toshev,Pfister,Li2014,Jain2013a,Jain2014,Tompson,Tompson2014}
\citation{Accv2014}
\citation{Gupta2014}
\citation{Schwarz2015}
\citation{Alexandre2013}
\citation{Paiement}
\citation{Chen2013}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Related Work}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Depth Imaging}{3}{subsection.2.1}}
\newlabel{sec:Depth}{{2.1}{3}{Depth Imaging}{subsection.2.1}{}}
\citation{Han2013}
\citation{Zhang2012a,Khoshelham2012a}
\citation{Han2013}
\citation{Han2013}
\citation{Gonzalez-Jorge2013}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The process by which depth is computed from triangulation of structured light. From \cite  {Han2013} \relax }}{4}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:kinectMeasure}{{1}{4}{The process by which depth is computed from triangulation of structured light. From \cite {Han2013} \relax }{figure.caption.1}{}}
\citation{Han2013}
\citation{StoyanovTodorandLouloudiAthanasiaandAndreassonHenrikandLilienthal2011a}
\citation{Khoshelham2012a}
\citation{Smisek2011}
\citation{Nguyen2012}
\citation{Feng2013}
\citation{Feng2013}
\citation{Feng2013}
\citation{Feng2013}
\citation{Khoshelham2012a,Smisek2011,Nguyen2012}
\citation{Fiedler2013}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Sensor Performance}{5}{subsubsection.2.1.1}}
\newlabel{sec:senPerf}{{2.1.1}{5}{Sensor Performance}{subsubsection.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Shows the holes in structured light depth data due to the different perspectives of IR projector and senor (regions\nobreakspace  {}1\nobreakspace  {}and\nobreakspace  {}3) and due to the surface of reflection being roughly\nobreakspace  {}5m away and at a large angle(region\nobreakspace  {}2) From\nobreakspace  {}\cite  {Feng2013}  \relax }}{6}{figure.caption.2}}
\newlabel{fig:kinectHoles4}{{2}{6}{Shows the holes in structured light depth data due to the different perspectives of IR projector and senor (regions~1~and~3) and due to the surface of reflection being roughly~5m away and at a large angle(region~2) From~\cite {Feng2013}  \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Shows the holes in depth data due abnormal reflections from certain glossy surfaces like the TV monitor and the subjects hair. From\nobreakspace  {}\cite  {Feng2013}  \relax }}{6}{figure.caption.3}}
\newlabel{fig:kinectHoles3}{{3}{6}{Shows the holes in depth data due abnormal reflections from certain glossy surfaces like the TV monitor and the subjects hair. From~\cite {Feng2013}  \relax }{figure.caption.3}{}}
\citation{Forsyth2005}
\citation{Moeslund2006,Hen2009,Poppe2007,Sminchisescu2006,Liu2015}
\citation{Poppe2007}
\citation{Sminchisescu2003}
\citation{Hen2009}
\citation{Hen2009,Agarwal2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Human Pose Estimation}{7}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Human Pose Estimation Using Dimensionality Reduction}{7}{subsubsection.2.2.1}}
\citation{Brand1999,Elgammal2004}
\citation{Elgammal2004}
\citation{Poggio1990}
\citation{Elgammal2004}
\citation{Elgammal2004b}
\citation{Elgammal2004}
\citation{Elgammal2004}
\citation{Brand1999}
\citation{Urtasun2005}
\citation{Lawrence2004}
\citation{Tangkuampien2006}
\citation{Rosales2000,Rosales2001}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  The 1D gait manifold produced from LLE dimensionality reduction on images of shilouttes used by Elgammal et al. to simplify joint tracking. From\nobreakspace  {}\cite  {Elgammal2004}.  \relax }}{9}{figure.caption.4}}
\newlabel{fig:elg}{{4}{9}{The 1D gait manifold produced from LLE dimensionality reduction on images of shilouttes used by Elgammal et al. to simplify joint tracking. From~\cite {Elgammal2004}.  \relax }{figure.caption.4}{}}
\citation{Helten2013}
\citation{Han2013,Giovanni}
\citation{Shotton2011}
\citation{Shotton2011}
\citation{Shotton2011}
\citation{Shotton2011}
\citation{Shotton2011}
\citation{Shotton2013a}
\citation{Shotton2011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Human Pose Estimation From Depth Images}{10}{subsubsection.2.2.2}}
\newlabel{eq:dcf}{{1}{10}{Human Pose Estimation From Depth Images}{equation.2.1}{}}
\citation{Plagemann2010}
\citation{Ye2011,Wei2011,Baak2011,Zhu2008}
\citation{Chan2014}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example the depth comparison features from equation \ref  {eq:dcf} used in \cite  {Shotton2011} to perform per pixel body part classification. The yellow crosses indicate the image pixel $\boldsymbol  {u}$ being classified. The red circles indicate the offset pixels as defined in equation \ref  {eq:dcf}. They use random forrests which combine many such features to give a strong discriminative signal. From\nobreakspace  {}\cite  {Shotton2011}  \relax }}{11}{figure.caption.5}}
\newlabel{fig:dcf}{{5}{11}{An example the depth comparison features from equation \ref {eq:dcf} used in \cite {Shotton2011} to perform per pixel body part classification. The yellow crosses indicate the image pixel $\boldsymbol {u}$ being classified. The red circles indicate the offset pixels as defined in equation \ref {eq:dcf}. They use random forrests which combine many such features to give a strong discriminative signal. From~\cite {Shotton2011}  \relax }{figure.caption.5}{}}
\citation{KarLects}
\citation{KarLects}
\citation{KarLects}
\citation{KarLects}
\citation{Rumelhart1986}
\citation{Crabbe2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Convolutional Neural Networks}{12}{subsection.2.3}}
\newlabel{eq:networkF}{{2}{12}{Convolutional Neural Networks}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Shows a representation of the activations produced following a number of convolution layers, non-linearities (Rectified Linear Units, or ReLUs, are the function $max(0,x)$ and pooling layers. The network, an online demo from \cite  {KarLects}, is classifying images from the CIFAR-10 dataset using the ConvnetJS library\footnotemark . )  \relax }}{13}{figure.caption.6}}
\newlabel{fig:convnet}{{6}{13}{Shows a representation of the activations produced following a number of convolution layers, non-linearities (Rectified Linear Units, or ReLUs, are the function $max(0,x)$ and pooling layers. The network, an online demo from \cite {KarLects}, is classifying images from the CIFAR-10 dataset using the ConvnetJS library\protect \footnotemark . )  \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Shows the effect of pooling layers in a CNN. From\nobreakspace  {}\cite  {KarLects}  \relax }}{13}{figure.caption.7}}
\newlabel{fig:pool}{{7}{13}{Shows the effect of pooling layers in a CNN. From~\cite {KarLects}  \relax }{figure.caption.7}{}}
\citation{Shotton2011}
\citation{Chan2014}
\citation{Krizhevsky2012}
\citation{Russakovsky}
\citation{Seung1992,Vapnik1994}
\citation{LeCun1998}
\newlabel{eq:errorCap}{{3}{14}{Convolutional Neural Networks}{equation.2.3}{}}
\citation{Szegedy2014}
\citation{Sharif2014,Donahue2014,Oquab2014,Girshick2014,Yosinski2014}
\citation{Schwarz2015,Alexandre2013}
\citation{Jain2013a}
\citation{Jain2014}
\citation{Toshev}
\citation{Krizhevsky2012}
\citation{Accv2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Human Pose Estimation Using CNNs}{15}{subsubsection.2.3.1}}
\newlabel{sec:HpeCnn}{{2.3.1}{15}{Human Pose Estimation Using CNNs}{subsubsection.2.3.1}{}}
\citation{Pfister}
\citation{Sermanet2013a}
\citation{Belagiannis}
\citation{Paiement}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{16}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Preprocessing}{16}{subsection.3.1}}
\newlabel{sec:preprocessing}{{3.1}{16}{Data Preprocessing}{subsection.3.1}{}}
\citation{Paiement}
\citation{Coifman2006}
\citation{Paiement}
\citation{Tao}
\citation{Tao}
\citation{Paiement}
\citation{Tao}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Skeleton Preprocessing}{17}{subsubsection.3.1.1}}
\newlabel{sec:skelPreproc}{{3.1.1}{17}{Skeleton Preprocessing}{subsubsection.3.1.1}{}}
\newlabel{fig:sub1}{{8a}{18}{Subfigure 8a}{subfigure.8.1}{}}
\newlabel{sub@fig:sub1}{{(a)}{a}{Subfigure 8a\relax }{subfigure.8.1}{}}
\newlabel{fig:sub2}{{8b}{18}{Subfigure 8b}{subfigure.8.2}{}}
\newlabel{sub@fig:sub2}{{(b)}{b}{Subfigure 8b\relax }{subfigure.8.2}{}}
\newlabel{fig:sub3}{{8c}{18}{Subfigure 8c}{subfigure.8.3}{}}
\newlabel{sub@fig:sub3}{{(c)}{c}{Subfigure 8c\relax }{subfigure.8.3}{}}
\newlabel{fig:sub4}{{8d}{18}{Subfigure 8d}{subfigure.8.4}{}}
\newlabel{sub@fig:sub4}{{(d)}{d}{Subfigure 8d\relax }{subfigure.8.4}{}}
\newlabel{fig:sub5}{{8e}{18}{Subfigure 8e}{subfigure.8.5}{}}
\newlabel{sub@fig:sub5}{{(e)}{e}{Subfigure 8e\relax }{subfigure.8.5}{}}
\newlabel{fig:sub6}{{8f}{18}{Subfigure 8f}{subfigure.8.6}{}}
\newlabel{sub@fig:sub6}{{(f)}{f}{Subfigure 8f\relax }{subfigure.8.6}{}}
\newlabel{fig:sub7}{{8g}{18}{Subfigure 8g}{subfigure.8.7}{}}
\newlabel{sub@fig:sub7}{{(g)}{g}{Subfigure 8g\relax }{subfigure.8.7}{}}
\newlabel{fig:sub8}{{8h}{18}{Subfigure 8h}{subfigure.8.8}{}}
\newlabel{sub@fig:sub8}{{(h)}{h}{Subfigure 8h\relax }{subfigure.8.8}{}}
\newlabel{fig:sub9}{{8i}{18}{Subfigure 8i}{subfigure.8.9}{}}
\newlabel{sub@fig:sub9}{{(i)}{i}{Subfigure 8i\relax }{subfigure.8.9}{}}
\newlabel{fig:sub10}{{8j}{18}{Subfigure 8j}{subfigure.8.10}{}}
\newlabel{sub@fig:sub10}{{(j)}{j}{Subfigure 8j\relax }{subfigure.8.10}{}}
\newlabel{fig:sub11}{{8k}{18}{Subfigure 8k}{subfigure.8.11}{}}
\newlabel{sub@fig:sub11}{{(k)}{k}{Subfigure 8k\relax }{subfigure.8.11}{}}
\newlabel{fig:sub12}{{8l}{18}{Subfigure 8l}{subfigure.8.12}{}}
\newlabel{sub@fig:sub12}{{(l)}{l}{Subfigure 8l\relax }{subfigure.8.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The subjects contained in the SPHERE staircase 2014 dataset.\relax }}{18}{figure.caption.8}}
\newlabel{fig:subjects}{{8}{18}{The subjects contained in the SPHERE staircase 2014 dataset.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 1.  }}}{18}{subfigure.8.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 2.  }}}{18}{subfigure.8.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Subject 3.  }}}{18}{subfigure.8.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Subject 4.  }}}{18}{subfigure.8.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Subject 5.  }}}{18}{subfigure.8.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Subject 6.  }}}{18}{subfigure.8.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {Subject 7.  }}}{18}{subfigure.8.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {Subject 8.  }}}{18}{subfigure.8.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {Subject 9.  }}}{18}{subfigure.8.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {Subject 10.  }}}{18}{subfigure.8.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {Subject 11.  }}}{18}{subfigure.8.11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {Subject 12.  }}}{18}{subfigure.8.12}}
\citation{Paiement}
\citation{Tao}
\citation{Paiement}
\citation{Paiement}
\citation{Camplani2012a}
\citation{Camplani2012a}
\citation{Camplani2012a}
\citation{Camplani2012a}
\citation{bgslibrary}
\citation{Zivkovic2004}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Depth Preprocessing}{20}{subsubsection.3.1.2}}
\newlabel{fig:1-6manifoldNoFlips}{{9a}{21}{Subfigure 9a}{subfigure.9.1}{}}
\newlabel{sub@fig:1-6manifoldNoFlips}{{(a)}{a}{Subfigure 9a\relax }{subfigure.9.1}{}}
\newlabel{fig:1-6manifoldWFlips}{{9b}{21}{Subfigure 9b}{subfigure.9.2}{}}
\newlabel{sub@fig:1-6manifoldWFlips}{{(b)}{b}{Subfigure 9b\relax }{subfigure.9.2}{}}
\newlabel{fig:1-12maniWFlips}{{9c}{21}{Subfigure 9c}{subfigure.9.3}{}}
\newlabel{sub@fig:1-12maniWFlips}{{(c)}{c}{Subfigure 9c\relax }{subfigure.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Shows the pose manifolds used in this work.\relax }}{21}{figure.caption.9}}
\newlabel{fig:manifolds}{{9}{21}{Shows the pose manifolds used in this work.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {The manifold produced by normal sequences of subjects 1-6. This was the form used in\nobreakspace {}\cite {Paiement}. We connect points from neighbouring frames for better visualisation of the structure.  }}}{21}{subfigure.9.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {The manifold produced by normal sequences of subjects 1-6 including their horizontal flips. This was the form used in this work.}}}{21}{subfigure.9.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {The manifold produced by all sequences including their flips. The larger variation in the z component (the vertical axis in the figure) led to lower network accuracy and incorrect normality analysis.  }}}{21}{subfigure.9.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Shows the skeleton to manifold mapping. Normal gait sequences trace paths between the two corners on the right, with the postion of maximal knee flex the turning point. The left most coner of the manifold consists of elongated skeletons which tend to be measured when the subject is too close to the sensor. \relax }}{22}{figure.caption.10}}
\newlabel{fig:skelToManifod}{{10}{22}{Shows the skeleton to manifold mapping. Normal gait sequences trace paths between the two corners on the right, with the postion of maximal knee flex the turning point. The left most coner of the manifold consists of elongated skeletons which tend to be measured when the subject is too close to the sensor. \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Shows all manifold points in red. After image pre-processing we retain only those in the blue area. \relax }}{23}{figure.caption.11}}
\newlabel{fig:manifoldAfterImageProcessing}{{11}{23}{Shows all manifold points in red. After image pre-processing we retain only those in the blue area. \relax }{figure.caption.11}{}}
\newlabel{fig:-1.165-0.6517}{{12a}{23}{Subfigure 12a}{subfigure.12.1}{}}
\newlabel{sub@fig:-1.165-0.6517}{{(a)}{a}{Subfigure 12a\relax }{subfigure.12.1}{}}
\newlabel{fig:0.9485,-0.1622}{{12b}{23}{Subfigure 12b}{subfigure.12.2}{}}
\newlabel{sub@fig:0.9485,-0.1622}{{(b)}{b}{Subfigure 12b\relax }{subfigure.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Shows skeletons within 0.02 of the same Y[0],Y[1] postition but with maximum difference in Y[2]. Red skeletons are mimimum Y[2], black are maximum. We find no clear difference between the Skeleton of minimum and maximum Y[2]. This is reflected by the CNN which measures this coordinate with a lower accuracy than the first two.\relax }}{23}{figure.caption.12}}
\newlabel{fig:skelsZcomp}{{12}{23}{Shows skeletons within 0.02 of the same Y[0],Y[1] postition but with maximum difference in Y[2]. Red skeletons are mimimum Y[2], black are maximum. We find no clear difference between the Skeleton of minimum and maximum Y[2]. This is reflected by the CNN which measures this coordinate with a lower accuracy than the first two.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Difference of 0.4099 }}}{23}{subfigure.12.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Difference of 0.503. }}}{23}{subfigure.12.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Each normal sequence of the first 6 subjects plotted in a different colour. We observe that Y[2] coordinates for each subject tend to ramain within a sub-region of full range. This finding promoted the use of subject finetuning which improves the accuracy of Y[2] predictions. \relax }}{24}{figure.caption.13}}
\newlabel{fig:subjectsOnManifold}{{13}{24}{Each normal sequence of the first 6 subjects plotted in a different colour. We observe that Y[2] coordinates for each subject tend to ramain within a sub-region of full range. This finding promoted the use of subject finetuning which improves the accuracy of Y[2] predictions. \relax }{figure.caption.13}{}}
\newlabel{fig:depthWithHoles}{{14a}{25}{Subfigure 14a}{subfigure.14.1}{}}
\newlabel{sub@fig:depthWithHoles}{{(a)}{a}{Subfigure 14a\relax }{subfigure.14.1}{}}
\newlabel{fig:camplaniCleaned}{{14b}{25}{Subfigure 14b}{subfigure.14.2}{}}
\newlabel{sub@fig:camplaniCleaned}{{(b)}{b}{Subfigure 14b\relax }{subfigure.14.2}{}}
\newlabel{fig:quickFilled}{{14c}{25}{Subfigure 14c}{subfigure.14.3}{}}
\newlabel{sub@fig:quickFilled}{{(c)}{c}{Subfigure 14c\relax }{subfigure.14.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A comparison of hole filling methods. We use the max fill method. \relax }}{25}{figure.caption.14}}
\newlabel{fig:filtering}{{14}{25}{A comparison of hole filling methods. We use the max fill method. \relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Typical image before hole filling.  }}}{25}{subfigure.14.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Filter and filled using a simplifed version of\nobreakspace {}\cite {Camplani2012a}.  }}}{25}{subfigure.14.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Filled using max fill method.  }}}{25}{subfigure.14.3}}
\citation{Belagiannis}
\citation{Krizhevsky2012}
\citation{Krizhevsky2012}
\citation{LeCun1998a,Bottou2010,LeCun2012}
\citation{Jia2014}
\citation{Chen,Pfister,Girshick2014,Springenberg2015,Schwarz2015,Simonyan2015,Wang2015}
\newlabel{fig:blackBG}{{15a}{28}{Subfigure 15a}{subfigure.15.1}{}}
\newlabel{sub@fig:blackBG}{{(a)}{a}{Subfigure 15a\relax }{subfigure.15.1}{}}
\newlabel{fig:meanBG}{{15b}{28}{Subfigure 15b}{subfigure.15.2}{}}
\newlabel{sub@fig:meanBG}{{(b)}{b}{Subfigure 15b\relax }{subfigure.15.2}{}}
\newlabel{fig:adjusted}{{15c}{28}{Subfigure 15c}{subfigure.15.3}{}}
\newlabel{sub@fig:adjusted}{{(c)}{c}{Subfigure 15c\relax }{subfigure.15.3}{}}
\newlabel{fig:rgb}{{15d}{28}{Subfigure 15d}{subfigure.15.4}{}}
\newlabel{sub@fig:rgb}{{(d)}{d}{Subfigure 15d\relax }{subfigure.15.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Shows the input image colour schemes tested with the CNN. We found (c) produced the largest responses in the first layer filters of a pre-trained network, shown in figure \ref  {fig:colourschemeActivations}\relax }}{28}{figure.caption.15}}
\newlabel{fig:colourschemes}{{15}{28}{Shows the input image colour schemes tested with the CNN. We found (c) produced the largest responses in the first layer filters of a pre-trained network, shown in figure \ref {fig:colourschemeActivations}\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Initial scheme.  }}}{28}{subfigure.15.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Mean background method.  }}}{28}{subfigure.15.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Final scheme.  }}}{28}{subfigure.15.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Pre-processed RGB  }}}{28}{subfigure.15.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}RGB Pre-processing}{28}{subsubsection.3.1.3}}
\newlabel{fig:layer1filts}{{16a}{29}{Subfigure 16a}{subfigure.16.1}{}}
\newlabel{sub@fig:layer1filts}{{(a)}{a}{Subfigure 16a\relax }{subfigure.16.1}{}}
\newlabel{fig:blackBGactiv}{{16b}{29}{Subfigure 16b}{subfigure.16.2}{}}
\newlabel{sub@fig:blackBGactiv}{{(b)}{b}{Subfigure 16b\relax }{subfigure.16.2}{}}
\newlabel{fig:meanBGactiv}{{16c}{29}{Subfigure 16c}{subfigure.16.3}{}}
\newlabel{sub@fig:meanBGactiv}{{(c)}{c}{Subfigure 16c\relax }{subfigure.16.3}{}}
\newlabel{fig:adjustedActiv}{{16d}{29}{Subfigure 16d}{subfigure.16.4}{}}
\newlabel{sub@fig:adjustedActiv}{{(d)}{d}{Subfigure 16d\relax }{subfigure.16.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The activations produced by the first layer filters (a) for each of the colour schemes of figure \ref  {fig:colourschemes}. \relax }}{29}{figure.caption.16}}
\newlabel{fig:colourschemeActivations}{{16}{29}{The activations produced by the first layer filters (a) for each of the colour schemes of figure \ref {fig:colourschemes}. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {The filters in conv1 of a imagenet pre-trained then finetuned AlexNet \cite {Krizhevsky2012}.  }}}{29}{subfigure.16.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Initial colouring scheme  }}}{29}{subfigure.16.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Mean background method  }}}{29}{subfigure.16.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Final scheme  }}}{29}{subfigure.16.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Shows the network accuracy against number of training examples when using mean subtracted data and non mean subtracted data. The accuracy of network predictions was seen to decrease when using mean subtracted data, hence we abandon this common practise.\relax }}{30}{figure.caption.17}}
\newlabel{fig:meanSubComp}{{17}{30}{Shows the network accuracy against number of training examples when using mean subtracted data and non mean subtracted data. The accuracy of network predictions was seen to decrease when using mean subtracted data, hence we abandon this common practise.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Shows the network accuracy when using the RGB images only, the depth image replicated for each of the 3 channels only, and a combination of the two which consisted of 1 chanel of the average of red and green, 1 channel of green and blue averaged and the depth in the final channel. We use depth only for final resutls. \relax }}{30}{figure.caption.18}}
\newlabel{fig:rgbdcomp}{{18}{30}{Shows the network accuracy when using the RGB images only, the depth image replicated for each of the 3 channels only, and a combination of the two which consisted of 1 chanel of the average of red and green, 1 channel of green and blue averaged and the depth in the final channel. We use depth only for final resutls. \relax }{figure.caption.18}{}}
\citation{Folk2011}
\citation{Krizhevsky2012}
\citation{Krizhevsky2012}
\citation{Krizhevsky2012}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  The achitecture of\nobreakspace  {}\cite  {Krizhevsky2012} is used.\relax }}{31}{figure.caption.19}}
\newlabel{fig:alexNet}{{19}{31}{The achitecture of~\cite {Krizhevsky2012} is used.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Software}{31}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Architecture}{31}{subsection.3.3}}
\newlabel{sec:alexNet}{{3.3}{31}{Architecture}{subsection.3.3}{}}
\citation{Krizhevsky2012}
\newlabel{fig:conv1}{{20a}{32}{Subfigure 20a}{subfigure.20.1}{}}
\newlabel{sub@fig:conv1}{{(a)}{a}{Subfigure 20a\relax }{subfigure.20.1}{}}
\newlabel{fig:norm1}{{20b}{32}{Subfigure 20b}{subfigure.20.2}{}}
\newlabel{sub@fig:norm1}{{(b)}{b}{Subfigure 20b\relax }{subfigure.20.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Shows the effect of Local Response Normalisation on 1st layer activations. \relax }}{32}{figure.caption.20}}
\newlabel{fig:LRN}{{20}{32}{Shows the effect of Local Response Normalisation on 1st layer activations. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {The activations before LRN.  }}}{32}{subfigure.20.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {And after  }}}{32}{subfigure.20.2}}
\citation{Simonyan2015}
\citation{Chatfield2014}
\citation{fig:norm1}
\citation{Krizhevsky2012}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Shows a validation set loss for various pre-training schemes. We find that begining training from ImageNet pretrained weights throughout the network hinders performance. Using pre-trained weights only in the first two layers produced the best results. We use this strategy for our final tests. \relax }}{33}{figure.caption.21}}
\newlabel{fig:alexNetpre}{{21}{33}{Shows a validation set loss for various pre-training schemes. We find that begining training from ImageNet pretrained weights throughout the network hinders performance. Using pre-trained weights only in the first two layers produced the best results. We use this strategy for our final tests. \relax }{figure.caption.21}{}}
\citation{KarLects}
\citation{Belagiannis}
\citation{Li2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Regression Vs. Classification}{34}{subsubsection.3.3.1}}
\citation{Duchi2011}
\newlabel{fig:wClasses51}{{22a}{35}{Subfigure 22a}{subfigure.22.1}{}}
\newlabel{sub@fig:wClasses51}{{(a)}{a}{Subfigure 22a\relax }{subfigure.22.1}{}}
\newlabel{fig:wClasses500s}{{22b}{35}{Subfigure 22b}{subfigure.22.2}{}}
\newlabel{sub@fig:wClasses500s}{{(b)}{b}{Subfigure 22b\relax }{subfigure.22.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Top 3 graphs show plot the 3 components of the pose vector for the labels (red), and the the network prediction (blue) for a classification network. The 4th plot shows the error measured as the distance between the labels and prediction. A mean loss of 0.13 for this sequence was achieved using pure regression. \relax }}{35}{figure.caption.22}}
\newlabel{fig:classesRes}{{22}{35}{Top 3 graphs show plot the 3 components of the pose vector for the labels (red), and the the network prediction (blue) for a classification network. The 4th plot shows the error measured as the distance between the labels and prediction. A mean loss of 0.13 for this sequence was achieved using pure regression. \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {With 51 classes per component. Mean\nobreakspace {}loss\nobreakspace {}=\nobreakspace {}0.6035 std\nobreakspace {}=\nobreakspace {}0.3154.  }}}{35}{subfigure.22.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {With 500 classes per component. Mean\nobreakspace {}loss\nobreakspace {}=\nobreakspace {}0.7141 std\nobreakspace {}=\nobreakspace {}0.3054.  }}}{35}{subfigure.22.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Training Details}{35}{subsection.3.4}}
\citation{Paiement}
\citation{Paiement}
\citation{Paiement}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{36}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Fine Tuning}{36}{subsection.4.1}}
\newlabel{sec:finetuning}{{4.1}{36}{Fine Tuning}{subsection.4.1}{}}
\newlabel{fig:s1}{{23a}{37}{Subfigure 23a}{subfigure.23.1}{}}
\newlabel{sub@fig:s1}{{(a)}{a}{Subfigure 23a\relax }{subfigure.23.1}{}}
\newlabel{fig:s1FT}{{23b}{37}{Subfigure 23b}{subfigure.23.2}{}}
\newlabel{sub@fig:s1FT}{{(b)}{b}{Subfigure 23b\relax }{subfigure.23.2}{}}
\newlabel{fig:s2}{{23c}{37}{Subfigure 23c}{subfigure.23.3}{}}
\newlabel{sub@fig:s2}{{(c)}{c}{Subfigure 23c\relax }{subfigure.23.3}{}}
\newlabel{fig:s2FT}{{23d}{37}{Subfigure 23d}{subfigure.23.4}{}}
\newlabel{sub@fig:s2FT}{{(d)}{d}{Subfigure 23d\relax }{subfigure.23.4}{}}
\newlabel{fig:s3}{{23e}{37}{Subfigure 23e}{subfigure.23.5}{}}
\newlabel{sub@fig:s3}{{(e)}{e}{Subfigure 23e\relax }{subfigure.23.5}{}}
\newlabel{fig:s1FT}{{23f}{37}{Subfigure 23f}{subfigure.23.6}{}}
\newlabel{sub@fig:s1FT}{{(f)}{f}{Subfigure 23f\relax }{subfigure.23.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1207, std\nobreakspace {}=\nobreakspace {}0.1604. }}}{37}{subfigure.23.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1227 std\nobreakspace {}=\nobreakspace {}0.1497.  }}}{37}{subfigure.23.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.3859, std\nobreakspace {}=\nobreakspace {}0.3678. }}}{37}{subfigure.23.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.2280 std\nobreakspace {}=\nobreakspace {}0.2457.  }}}{37}{subfigure.23.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1648, std\nobreakspace {}=\nobreakspace {}0.2772. }}}{37}{subfigure.23.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1465 std\nobreakspace {}=\nobreakspace {}0.2713.  }}}{37}{subfigure.23.6}}
\newlabel{fig:s4}{{22g}{38}{Subfigure 22g}{subfigure.22.7}{}}
\newlabel{sub@fig:s4}{{(g)}{g}{Subfigure 22g\relax }{subfigure.22.7}{}}
\newlabel{fig:s4FT}{{22h}{38}{Subfigure 22h}{subfigure.22.8}{}}
\newlabel{sub@fig:s4FT}{{(h)}{h}{Subfigure 22h\relax }{subfigure.22.8}{}}
\newlabel{fig:s5}{{22i}{38}{Subfigure 22i}{subfigure.22.9}{}}
\newlabel{sub@fig:s5}{{(i)}{i}{Subfigure 22i\relax }{subfigure.22.9}{}}
\newlabel{fig:s5FT}{{22j}{38}{Subfigure 22j}{subfigure.22.10}{}}
\newlabel{sub@fig:s5FT}{{(j)}{j}{Subfigure 22j\relax }{subfigure.22.10}{}}
\newlabel{fig:s6}{{22k}{38}{Subfigure 22k}{subfigure.22.11}{}}
\newlabel{sub@fig:s6}{{(k)}{k}{Subfigure 22k\relax }{subfigure.22.11}{}}
\newlabel{fig:s6FT}{{22l}{38}{Subfigure 22l}{subfigure.22.12}{}}
\newlabel{sub@fig:s6FT}{{(l)}{l}{Subfigure 22l\relax }{subfigure.22.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Top 3 graphs show the 3 components of the pose vector for the labels (red), and the the network prediction (blue). The 4th plot shows the error measured as the distance between the labels and predictions. Fine tuned results are produced by network which have been trained with spare sequences of the subject being tested. \relax }}{38}{figure.caption.24}}
\newlabel{fig:s1-6}{{21}{38}{Top 3 graphs show the 3 components of the pose vector for the labels (red), and the the network prediction (blue). The 4th plot shows the error measured as the distance between the labels and predictions. Fine tuned results are produced by network which have been trained with spare sequences of the subject being tested. \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1613, std\nobreakspace {}=\nobreakspace {}0.1109. }}}{38}{subfigure.22.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0852 std\nobreakspace {}=\nobreakspace {}0.1030.  }}}{38}{subfigure.22.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1640, std\nobreakspace {}=\nobreakspace {}0.1450. }}}{38}{subfigure.22.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0751 std\nobreakspace {}=\nobreakspace {}0.0751.  }}}{38}{subfigure.22.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1952, std\nobreakspace {}=\nobreakspace {}0.1884. }}}{38}{subfigure.22.11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0873 std\nobreakspace {}=\nobreakspace {}0.0970.  }}}{38}{subfigure.22.12}}
\newlabel{fig:s7}{{22a}{39}{Subfigure 22a}{subfigure.22.1}{}}
\newlabel{sub@fig:s7}{{(a)}{a}{Subfigure 22a\relax }{subfigure.22.1}{}}
\newlabel{fig:s7FT}{{22b}{39}{Subfigure 22b}{subfigure.22.2}{}}
\newlabel{sub@fig:s7FT}{{(b)}{b}{Subfigure 22b\relax }{subfigure.22.2}{}}
\newlabel{fig:s8}{{22c}{39}{Subfigure 22c}{subfigure.22.3}{}}
\newlabel{sub@fig:s8}{{(c)}{c}{Subfigure 22c\relax }{subfigure.22.3}{}}
\newlabel{fig:s2FT}{{22d}{39}{Subfigure 22d}{subfigure.22.4}{}}
\newlabel{sub@fig:s2FT}{{(d)}{d}{Subfigure 22d\relax }{subfigure.22.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1208, std\nobreakspace {}=\nobreakspace {}0.1388. }}}{39}{subfigure.22.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1133 std\nobreakspace {}=\nobreakspace {}0.1439.  }}}{39}{subfigure.22.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0457, std\nobreakspace {}=\nobreakspace {}0.0720. }}}{39}{subfigure.22.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0795 std\nobreakspace {}=\nobreakspace {}0.0950.  }}}{39}{subfigure.22.4}}
\newlabel{fig:s9n1}{{21e}{40}{Subfigure 21e}{subfigure.21.5}{}}
\newlabel{sub@fig:s9n1}{{(e)}{e}{Subfigure 21e\relax }{subfigure.21.5}{}}
\newlabel{fig:s9n1FT}{{21f}{40}{Subfigure 21f}{subfigure.21.6}{}}
\newlabel{sub@fig:s9n1FT}{{(f)}{f}{Subfigure 21f\relax }{subfigure.21.6}{}}
\newlabel{fig:s3}{{21g}{40}{Subfigure 21g}{subfigure.21.7}{}}
\newlabel{sub@fig:s3}{{(g)}{g}{Subfigure 21g\relax }{subfigure.21.7}{}}
\newlabel{fig:s9rlFT}{{21h}{40}{Subfigure 21h}{subfigure.21.8}{}}
\newlabel{sub@fig:s9rlFT}{{(h)}{h}{Subfigure 21h\relax }{subfigure.21.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1110, std\nobreakspace {}=\nobreakspace {}0.0995. }}}{40}{subfigure.21.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0692 std\nobreakspace {}=\nobreakspace {}0.0852.  }}}{40}{subfigure.21.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0944, std\nobreakspace {}=\nobreakspace {}0.0875. }}}{40}{subfigure.21.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {mean loss\nobreakspace {}=0.0821 std\nobreakspace {}=\nobreakspace {}0.0917  }}}{40}{subfigure.21.8}}
\newlabel{fig:s10ll}{{20i}{41}{Subfigure 20i}{subfigure.20.9}{}}
\newlabel{sub@fig:s10ll}{{(i)}{i}{Subfigure 20i\relax }{subfigure.20.9}{}}
\newlabel{fig:s10llFT}{{20j}{41}{Subfigure 20j}{subfigure.20.10}{}}
\newlabel{sub@fig:s10llFT}{{(j)}{j}{Subfigure 20j\relax }{subfigure.20.10}{}}
\newlabel{fig:s11n2}{{20k}{41}{Subfigure 20k}{subfigure.20.11}{}}
\newlabel{sub@fig:s11n2}{{(k)}{k}{Subfigure 20k\relax }{subfigure.20.11}{}}
\newlabel{fig:s11n2FT}{{20l}{41}{Subfigure 20l}{subfigure.20.12}{}}
\newlabel{sub@fig:s11n2FT}{{(l)}{l}{Subfigure 20l\relax }{subfigure.20.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1937 std\nobreakspace {}=\nobreakspace {}0.2353. }}}{41}{subfigure.20.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {mean loss\nobreakspace {}=0.1575 std\nobreakspace {}=\nobreakspace {}0.2448  }}}{41}{subfigure.20.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1337, std\nobreakspace {}=\nobreakspace {}0.1083. }}}{41}{subfigure.20.11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.0474 std\nobreakspace {}=\nobreakspace {}0.0496  }}}{41}{subfigure.20.12}}
\newlabel{fig:s11sx2}{{19m}{42}{Subfigure 19m}{subfigure.19.13}{}}
\newlabel{sub@fig:s11sx2}{{(m)}{m}{Subfigure 19m\relax }{subfigure.19.13}{}}
\newlabel{fig:s11sx2FT}{{19n}{42}{Subfigure 19n}{subfigure.19.14}{}}
\newlabel{sub@fig:s11sx2FT}{{(n)}{n}{Subfigure 19n\relax }{subfigure.19.14}{}}
\newlabel{fig:s12n1}{{19o}{42}{Subfigure 19o}{subfigure.19.15}{}}
\newlabel{sub@fig:s12n1}{{(o)}{o}{Subfigure 19o\relax }{subfigure.19.15}{}}
\newlabel{fig:s12n1FT}{{19p}{42}{Subfigure 19p}{subfigure.19.16}{}}
\newlabel{sub@fig:s12n1FT}{{(p)}{p}{Subfigure 19p\relax }{subfigure.19.16}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(m)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1547, std\nobreakspace {}=\nobreakspace {}0.1231. }}}{42}{subfigure.19.13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(n)}{\ignorespaces {mean loss\nobreakspace {}=0.0867 std\nobreakspace {}=\nobreakspace {}0.0792  }}}{42}{subfigure.19.14}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(o)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1893, std\nobreakspace {}=\nobreakspace {}0.2492. }}}{42}{subfigure.19.15}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(p)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1673 std\nobreakspace {}=\nobreakspace {}0.2368  }}}{42}{subfigure.19.16}}
\newlabel{fig:s12rl}{{18q}{43}{Subfigure 18q}{subfigure.18.17}{}}
\newlabel{sub@fig:s12rl}{{(q)}{q}{Subfigure 18q\relax }{subfigure.18.17}{}}
\newlabel{fig:s12rlFT}{{18r}{43}{Subfigure 18r}{subfigure.18.18}{}}
\newlabel{sub@fig:s12rlFT}{{(r)}{r}{Subfigure 18r\relax }{subfigure.18.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Top 3 graphs show the 3 components of the pose vector for the labels (red), and the the network prediction (blue). The 4th plot shows the error measured as the distance between the labels and predictions. Fine tuned results are produced by network which have been trained with spare sequences of the subject being tested. 5th and 6th plots show the movement quality measurements of\nobreakspace  {}\cite  {Paiement} when given the network's prediction (blue) and the original results of the labels (red). The magenta dashed line shows the empirically determined abnormality threshold. \relax }}{43}{figure.caption.29}}
\newlabel{fig:s7-12}{{17}{43}{Top 3 graphs show the 3 components of the pose vector for the labels (red), and the the network prediction (blue). The 4th plot shows the error measured as the distance between the labels and predictions. Fine tuned results are produced by network which have been trained with spare sequences of the subject being tested. 5th and 6th plots show the movement quality measurements of~\cite {Paiement} when given the network's prediction (blue) and the original results of the labels (red). The magenta dashed line shows the empirically determined abnormality threshold. \relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(q)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1611, std\nobreakspace {}=\nobreakspace {}0.1334. }}}{43}{subfigure.18.17}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(r)}{\ignorespaces {mean loss\nobreakspace {}=\nobreakspace {}0.1097 std\nobreakspace {}=\nobreakspace {}0.1040  }}}{43}{subfigure.18.18}}
\newlabel{fig:ftS2}{{18a}{44}{Subfigure 18a}{subfigure.18.1}{}}
\newlabel{sub@fig:ftS2}{{(a)}{a}{Subfigure 18a\relax }{subfigure.18.1}{}}
\newlabel{fig:ftS6}{{18b}{44}{Subfigure 18b}{subfigure.18.2}{}}
\newlabel{sub@fig:ftS6}{{(b)}{b}{Subfigure 18b\relax }{subfigure.18.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Shows a plot of the skeleton/label data for each sequence of the subjects in which fine tuning produced the greatest decrease in the error of the network's predictions. \relax }}{44}{figure.caption.30}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 2. Fine tuning on Normal 1 and 2 produced a decrease in error of 0.1579 in 3. }}}{44}{subfigure.18.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 6. Fine tuning on Normal 1 and 2 produced a decrease in error of 0.1079 in 3.  }}}{44}{subfigure.18.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Shows a 3D plot of the skeleton data for Subject 8. Fine tuning on Normal 1 and 2 produced an increase in error of 0.0338 in the Stop x2 sequence.\relax }}{45}{figure.caption.31}}
\newlabel{fig:ftS8}{{19}{45}{Shows a 3D plot of the skeleton data for Subject 8. Fine tuning on Normal 1 and 2 produced an increase in error of 0.0338 in the Stop x2 sequence.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Network Errors Vs. Label Errors Vs. Image Errors}{45}{subsection.4.2}}
\citation{Shotton2012}
\newlabel{fig:ftS1_257Skel}{{20a}{46}{Subfigure 20a}{subfigure.20.1}{}}
\newlabel{sub@fig:ftS1_257Skel}{{(a)}{a}{Subfigure 20a\relax }{subfigure.20.1}{}}
\newlabel{fig:ftS1_257}{{20b}{46}{Subfigure 20b}{subfigure.20.2}{}}
\newlabel{sub@fig:ftS1_257}{{(b)}{b}{Subfigure 20b\relax }{subfigure.20.2}{}}
\newlabel{fig:ftS1_257}{{20c}{46}{Subfigure 20c}{subfigure.20.3}{}}
\newlabel{sub@fig:ftS1_257}{{(c)}{c}{Subfigure 20c\relax }{subfigure.20.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Shows the image label and prediction for frame 257 of subject 1 normal 1. The results (figure \ref  {fig:s1FT}) showed a large error at this frame. However we see that the Kinect skeleton has been confused by the occlusion of the left leg causing the skeleton to think that the left foot is in front of the right which we see from the depth image is not the case. The network is not fooled by this occlusion, predicting a point near the maximum $Y[0]$, the skeleton nearest to this point shows the right foot correctly in front of the left.\relax }}{46}{figure.caption.32}}
\newlabel{fig:ftS1_257skelAndIm}{{20}{46}{Shows the image label and prediction for frame 257 of subject 1 normal 1. The results (figure \ref {fig:s1FT}) showed a large error at this frame. However we see that the Kinect skeleton has been confused by the occlusion of the left leg causing the skeleton to think that the left foot is in front of the right which we see from the depth image is not the case. The network is not fooled by this occlusion, predicting a point near the maximum $Y[0]$, the skeleton nearest to this point shows the right foot correctly in front of the left.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Labelled skeleton. }}}{46}{subfigure.20.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Depth image.  }}}{46}{subfigure.20.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Skeleton nearest to network's prediction.  }}}{46}{subfigure.20.3}}
\newlabel{fig:badSkel1}{{21a}{48}{Subfigure 21a}{subfigure.21.1}{}}
\newlabel{sub@fig:badSkel1}{{(a)}{a}{Subfigure 21a\relax }{subfigure.21.1}{}}
\newlabel{fig:badSkel2}{{21b}{48}{Subfigure 21b}{subfigure.21.2}{}}
\newlabel{sub@fig:badSkel2}{{(b)}{b}{Subfigure 21b\relax }{subfigure.21.2}{}}
\newlabel{fig:badSkel3}{{21c}{48}{Subfigure 21c}{subfigure.21.3}{}}
\newlabel{sub@fig:badSkel3}{{(c)}{c}{Subfigure 21c\relax }{subfigure.21.3}{}}
\newlabel{fig:badSkel3}{{21d}{48}{Subfigure 21d}{subfigure.21.4}{}}
\newlabel{sub@fig:badSkel3}{{(d)}{d}{Subfigure 21d\relax }{subfigure.21.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Out of range skeleton errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. These are some of the tested images which produced the greatest errors, occuring at the begining of sequences where the subject is outside of the Kinects optimum range. We find that these errors can be attributed to poor ground truth with the network able to produce a more accurate measure provided that similar poses with correct labels do exist in the training data. \relax }}{48}{figure.caption.33}}
\newlabel{fig:badSkels}{{21}{48}{Out of range skeleton errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. These are some of the tested images which produced the greatest errors, occuring at the begining of sequences where the subject is outside of the Kinects optimum range. We find that these errors can be attributed to poor ground truth with the network able to produce a more accurate measure provided that similar poses with correct labels do exist in the training data. \relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 2 Normal 3 frame 117 loss = 1.13. Labelled skeleton has legs at a similiar depth, network's prediction has right leg far in front of left. }}}{48}{subfigure.21.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 3 Normal 1 frame 162 loss = 1.30. Labelled skeleton has right leg in front of left, network measures the opposite which is correct. }}}{48}{subfigure.21.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Subject 7 RL frame 75 loss = 0.97. Labelled skeleton is not accurate. The network also fails since this is a strange pose where the subject appears to be turning on to the stairs. Since there are few examples of poses of this kind in the training data, and the ones that are have bad skeletons we can not expect better performance.  }}}{48}{subfigure.21.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Subject 10 LL frame 165 loss = 2.63. Labelled skeleton legs crossed over right above left, network measures left leg forward correctly. }}}{48}{subfigure.21.4}}
\newlabel{fig:skelErr1}{{22a}{49}{Subfigure 22a}{subfigure.22.1}{}}
\newlabel{sub@fig:skelErr1}{{(a)}{a}{Subfigure 22a\relax }{subfigure.22.1}{}}
\newlabel{fig:skelErr2}{{22b}{49}{Subfigure 22b}{subfigure.22.2}{}}
\newlabel{sub@fig:skelErr2}{{(b)}{b}{Subfigure 22b\relax }{subfigure.22.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Skeleton errors: shows labelled skeletons and corresponding pose vector in circled in red and the network's prediction in blue. \relax }}{49}{figure.caption.34}}
\newlabel{fig:skelErrs}{{22}{49}{Skeleton errors: shows labelled skeletons and corresponding pose vector in circled in red and the network's prediction in blue. \relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 2 Normal 3 frame 275. Loss = 0.5178. The skeleton of this frame is determined to be inaccurate since relative leg positions disagree considerably with the depth image.  }}}{49}{subfigure.22.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 4 Normal 1 frame 205. Loss = 0.5738. The skeleton of this frame is determined to be inaccurate since there is a clear error in the left foot position being measured at the same position as the right due to occlusion.  }}}{49}{subfigure.22.2}}
\newlabel{fig:netErr1}{{23a}{50}{Subfigure 23a}{subfigure.23.1}{}}
\newlabel{sub@fig:netErr1}{{(a)}{a}{Subfigure 23a\relax }{subfigure.23.1}{}}
\newlabel{fig:netErr2}{{23b}{50}{Subfigure 23b}{subfigure.23.2}{}}
\newlabel{sub@fig:netErr2}{{(b)}{b}{Subfigure 23b\relax }{subfigure.23.2}{}}
\newlabel{fig:netErr3}{{23c}{50}{Subfigure 23c}{subfigure.23.3}{}}
\newlabel{sub@fig:netErr3}{{(c)}{c}{Subfigure 23c\relax }{subfigure.23.3}{}}
\newlabel{fig:netErr4}{{23d}{50}{Subfigure 23d}{subfigure.23.4}{}}
\newlabel{sub@fig:netErr4}{{(d)}{d}{Subfigure 23d\relax }{subfigure.23.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Network Errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. \relax }}{50}{figure.caption.35}}
\newlabel{fig:netErrs}{{23}{50}{Network Errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. \relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 2 Normal 3 frame 143 loss = 0.4268. The cause of errors in this sequence is discussed in section \ref {sec:finetuning}.  }}}{50}{subfigure.23.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 12 RL frame 167 loss = 0.3274.  }}}{50}{subfigure.23.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Subject 12 Normal 1 frame 253 loss = 0.3105.  }}}{50}{subfigure.23.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Subject 11 Stop x2 frame 311 loss = 0.2779.  }}}{50}{subfigure.23.4}}
\citation{Paiement}
\citation{Paiement}
\newlabel{fig:badIm1}{{24a}{51}{Subfigure 24a}{subfigure.24.1}{}}
\newlabel{sub@fig:badIm1}{{(a)}{a}{Subfigure 24a\relax }{subfigure.24.1}{}}
\newlabel{fig:badIm2}{{24b}{51}{Subfigure 24b}{subfigure.24.2}{}}
\newlabel{sub@fig:badIm2}{{(b)}{b}{Subfigure 24b\relax }{subfigure.24.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Image Errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. These are some of the tested images which produced the greatest errors. These errors can be attributed to images which were meant to be removed during preprocessing, either because of bad masks or because the subject was too close to the camera or because they were not fully turned towards the camera.\relax }}{51}{figure.caption.36}}
\newlabel{fig:badImages}{{24}{51}{Image Errors: shows labelled skeletons in red and the skeletons nearest to the network's predicted pose vector in blue for each of the images. These are some of the tested images which produced the greatest errors. These errors can be attributed to images which were meant to be removed during preprocessing, either because of bad masks or because the subject was too close to the camera or because they were not fully turned towards the camera.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 12 Normal 1 frame 239 loss = 1.06. A poor foreground mask slipped through the cuts due to its roughtly human shape and size.  }}}{51}{subfigure.24.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 10 LL frame 444 loss = 0.77. Subject is too close to the sensor; legs are not visible.  }}}{51}{subfigure.24.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Movement Quality}{51}{subsection.4.3}}
\newlabel{fig:s1err}{{25a}{52}{Subfigure 25a}{subfigure.25.1}{}}
\newlabel{sub@fig:s1err}{{(a)}{a}{Subfigure 25a\relax }{subfigure.25.1}{}}
\newlabel{fig:s2err}{{25b}{52}{Subfigure 25b}{subfigure.25.2}{}}
\newlabel{sub@fig:s2err}{{(b)}{b}{Subfigure 25b\relax }{subfigure.25.2}{}}
\newlabel{fig:s3err}{{25c}{52}{Subfigure 25c}{subfigure.25.3}{}}
\newlabel{sub@fig:s3err}{{(c)}{c}{Subfigure 25c\relax }{subfigure.25.3}{}}
\newlabel{fig:s4err}{{25d}{52}{Subfigure 25d}{subfigure.25.4}{}}
\newlabel{sub@fig:s4err}{{(d)}{d}{Subfigure 25d\relax }{subfigure.25.4}{}}
\newlabel{fig:s5err}{{25e}{52}{Subfigure 25e}{subfigure.25.5}{}}
\newlabel{sub@fig:s5err}{{(e)}{e}{Subfigure 25e\relax }{subfigure.25.5}{}}
\newlabel{fig:s6err}{{25f}{52}{Subfigure 25f}{subfigure.25.6}{}}
\newlabel{sub@fig:s6err}{{(f)}{f}{Subfigure 25f\relax }{subfigure.25.6}{}}
\newlabel{fig:s7err}{{25g}{52}{Subfigure 25g}{subfigure.25.7}{}}
\newlabel{sub@fig:s7err}{{(g)}{g}{Subfigure 25g\relax }{subfigure.25.7}{}}
\newlabel{fig:s8err}{{25h}{52}{Subfigure 25h}{subfigure.25.8}{}}
\newlabel{sub@fig:s8err}{{(h)}{h}{Subfigure 25h\relax }{subfigure.25.8}{}}
\newlabel{fig:s9err}{{25i}{52}{Subfigure 25i}{subfigure.25.9}{}}
\newlabel{sub@fig:s9err}{{(i)}{i}{Subfigure 25i\relax }{subfigure.25.9}{}}
\newlabel{fig:s9-2err}{{25j}{52}{Subfigure 25j}{subfigure.25.10}{}}
\newlabel{sub@fig:s9-2err}{{(j)}{j}{Subfigure 25j\relax }{subfigure.25.10}{}}
\newlabel{fig:s10err}{{25k}{52}{Subfigure 25k}{subfigure.25.11}{}}
\newlabel{sub@fig:s10err}{{(k)}{k}{Subfigure 25k\relax }{subfigure.25.11}{}}
\newlabel{fig:s11err}{{25l}{52}{Subfigure 25l}{subfigure.25.12}{}}
\newlabel{sub@fig:s11err}{{(l)}{l}{Subfigure 25l\relax }{subfigure.25.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0738 std\nobreakspace {}=\nobreakspace {}0.0698.  }}}{52}{subfigure.25.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.1932 std\nobreakspace {}=\nobreakspace {}0.2126.  }}}{52}{subfigure.25.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0650 std\nobreakspace {}=\nobreakspace {}0.0902.  }}}{52}{subfigure.25.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0669 std\nobreakspace {}=\nobreakspace {}0.0617.  }}}{52}{subfigure.25.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.1214 std\nobreakspace {}=\nobreakspace {}0.1167.  }}}{52}{subfigure.25.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0817 std\nobreakspace {}=\nobreakspace {}0.0895.  }}}{52}{subfigure.25.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0875 std\nobreakspace {}=\nobreakspace {}0.0698.  }}}{52}{subfigure.25.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.1932 std\nobreakspace {}=\nobreakspace {}0.2126.  }}}{52}{subfigure.25.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0650 std\nobreakspace {}=\nobreakspace {}0.0902.  }}}{52}{subfigure.25.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0942 std\nobreakspace {}=\nobreakspace {}0.1061.  }}}{52}{subfigure.25.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0941 std\nobreakspace {}=\nobreakspace {}0.1085.  }}}{52}{subfigure.25.11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0786 std\nobreakspace {}=\nobreakspace {}0.0693.  }}}{52}{subfigure.25.12}}
\newlabel{fig:s12err}{{24m}{53}{Subfigure 24m}{subfigure.24.13}{}}
\newlabel{sub@fig:s12err}{{(m)}{m}{Subfigure 24m\relax }{subfigure.24.13}{}}
\newlabel{fig:s12-2err}{{24n}{53}{Subfigure 24n}{subfigure.24.14}{}}
\newlabel{sub@fig:s12-2err}{{(n)}{n}{Subfigure 24n\relax }{subfigure.24.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Plots of the loss i.e. the distance between the labelled pose vector and the network's predicted pose vector for the subject fine tuned models. Every frame with loss greater than $1\sigma $ from the total mean is categorised as either a network error (red), an image error (magenta) or a skeleton error (green). Examples of each of these errors are shown in figures \ref  {fig:netErrs}, \ref  {fig:badImages} and \ref  {fig:skelErrs} respectively. The mean for each sequence is recomputed after excluding skeleton and image errors to give a more reliable estimate of the network's true precision. \relax }}{53}{figure.caption.38}}
\newlabel{fig:classedErr}{{23}{53}{Plots of the loss i.e. the distance between the labelled pose vector and the network's predicted pose vector for the subject fine tuned models. Every frame with loss greater than $1\sigma $ from the total mean is categorised as either a network error (red), an image error (magenta) or a skeleton error (green). Examples of each of these errors are shown in figures \ref {fig:netErrs}, \ref {fig:badImages} and \ref {fig:skelErrs} respectively. The mean for each sequence is recomputed after excluding skeleton and image errors to give a more reliable estimate of the network's true precision. \relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(m)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0815 std\nobreakspace {}=\nobreakspace {}0.0821.  }}}{53}{subfigure.24.13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(n)}{\ignorespaces {adjusted mean loss\nobreakspace {}=\nobreakspace {}0.0874 std\nobreakspace {}=\nobreakspace {}0.1030.  }}}{53}{subfigure.24.14}}
\newlabel{fig:diffCase1}{{24a}{53}{Subfigure 24a}{subfigure.24.1}{}}
\newlabel{sub@fig:diffCase1}{{(a)}{a}{Subfigure 24a\relax }{subfigure.24.1}{}}
\newlabel{fig:diffCase2}{{24b}{53}{Subfigure 24b}{subfigure.24.2}{}}
\newlabel{sub@fig:diffCase2}{{(b)}{b}{Subfigure 24b\relax }{subfigure.24.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Shows some borderline cases when attributing the causes for errors in figure \ref  {fig:classedErr}.\relax }}{53}{figure.caption.39}}
\newlabel{fig:diffCases}{{24}{53}{Shows some borderline cases when attributing the causes for errors in figure \ref {fig:classedErr}.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 11 Stop x2 frame 211 loss = 0.3881. A difficult case where the image and network's prediction seem plausible but the skeleton does too. In this case we give the skeleton the benefit of the doubt and assign a network error. }}}{53}{subfigure.24.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 12 Normal 1 frame 256 loss = 0.3511. Here the skeleton says the right knee is behind the left. Image seems to show them at equal depth so we assign a network error.  }}}{53}{subfigure.24.2}}
\bibstyle{plain}
\bibdata{library,myLib}
\citation{Paiement}
\citation{Tao}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Shows the dynamics quality model (colour) as a function of pose vector and movement stage. The black dots represent frames from the Subject 9 Normal 1 sequence after its division into gait cycles. The strongest indication of normality is the value of Y[0]. Y[2] has a much broader range of normal values.\relax }}{55}{figure.caption.40}}
\newlabel{fig:qualityHeatMap}{{25}{55}{Shows the dynamics quality model (colour) as a function of pose vector and movement stage. The black dots represent frames from the Subject 9 Normal 1 sequence after its division into gait cycles. The strongest indication of normality is the value of Y[0]. Y[2] has a much broader range of normal values.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Processing Time}{55}{subsection.4.4}}
\newlabel{fig:lrlom7}{{26a}{56}{Subfigure 26a}{subfigure.26.1}{}}
\newlabel{sub@fig:lrlom7}{{(a)}{a}{Subfigure 26a\relax }{subfigure.26.1}{}}
\newlabel{fig:lrlom10}{{26b}{56}{Subfigure 26b}{subfigure.26.2}{}}
\newlabel{sub@fig:lrlom10}{{(b)}{b}{Subfigure 26b\relax }{subfigure.26.2}{}}
\newlabel{fig:lrlom9}{{26c}{56}{Subfigure 26c}{subfigure.26.3}{}}
\newlabel{sub@fig:lrlom9}{{(c)}{c}{Subfigure 26c\relax }{subfigure.26.3}{}}
\newlabel{fig:lrlom92}{{26d}{56}{Subfigure 26d}{subfigure.26.4}{}}
\newlabel{sub@fig:lrlom92}{{(d)}{d}{Subfigure 26d\relax }{subfigure.26.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces \relax }}{56}{figure.caption.41}}
\newlabel{fig:lrlOverMeasure}{{26}{56}{\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subject 7 RL frame 116. Kinect skeleton measures left knee slightly in front of right but image shows to them at equal depth. }}}{56}{subfigure.26.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Subject 10 LL frame 365. Kinect skeleton measures right foot slightly in front of the left.  }}}{56}{subfigure.26.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Subject 9 RL frame 256.  }}}{56}{subfigure.26.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Subject 9 RL frame 188.  }}}{56}{subfigure.26.4}}
\citation{Paiement}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{57}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Abnormal Poses}{57}{subsection.5.1}}
\newlabel{sec:abnormals}{{5.1}{57}{Abnormal Poses}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{57}{section.6}}
\@writefile{toc}{\contentsline {section}{Appendices}{57}{section*.42}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Pre-existing SPHERE System For Movement Quality Analysis}{57}{Appendix.1.A}}
\newlabel{sec:exSys}{{A}{57}{Pre-existing SPHERE System For Movement Quality Analysis}{Appendix.1.A}{}}
\citation{Tao}
\citation{Coifman2006}
\@writefile{toc}{\contentsline {section}{\numberline {B}Networks}{59}{Appendix.1.B}}
\newlabel{sec:networkCodes}{{B}{59}{Networks}{Appendix.1.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}AlexNet}{59}{subsection.1.B.1}}
